# follow_health.py
"""
10ë…„ í›„ ë§Œì„±ì§ˆí™˜ ì‹œë‚˜ë¦¬ì˜¤ ì˜ˆì¸¡ í˜ì´ì§€ (ë£¨íŠ¸ ë°°ì¹˜ìš©)

- data/follow_sample.csv ë¡œë“œ â†’ T_ID=1 ì‚¬ìš©ì ëˆ„ì  ë°ì´í„° í•„í„°
- utils.preprocess.preprocess_followup() ìœ¼ë¡œ ì‹œê³„ì—´ ìš”ì•½ ì „ì²˜ë¦¬
- utils.model_utils.load_models(kind="follow") ë¡œ ëª¨ë¸ 3ì¢… ë¡œë“œ
- ì˜ˆì¸¡/í™•ë¥ /ì¤‘ìš”ë„ ì¶œë ¥ + GPT ìì—°ì–´ ì„¤ëª…
"""

import streamlit as st
import pandas as pd
import numpy as np

from utils.preprocess import preprocess_followup, column_meaning
from utils.model_utils import load_models
from utils.gpt_utils import generate_gpt_explanation


def render(go_home):
    st.title("ğŸ§¬ 10ë…„ í›„ ë§Œì„±ì§ˆí™˜ ì‹œë‚˜ë¦¬ì˜¤ ì˜ˆì¸¡ê¸°")
    st.write("ì§€ê¸ˆê¹Œì§€ ê¸°ë¡í•´ì£¼ì‹  ìƒí™œìŠµê´€ì„ ë°”íƒ•ìœ¼ë¡œ 10ë…„ í›„ ë§Œì„±ì§ˆí™˜ ìœ„í—˜ë„ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")

    if st.button("â¬… í™ˆìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
        go_home()

    st.divider()

    if st.button("ì˜ˆì¸¡í•˜ê¸°"):
        try:
            with st.spinner("ì˜ˆì¸¡ì„ ì¤€ë¹„í•˜ëŠ” ì¤‘..."):
                # 1) ë°ì´í„° ë¡œë“œ
                df = pd.read_csv("data/follow_sample.csv", encoding="utf-8-sig")

                # ë‚ ì§œ/ID ì•ˆì „ ìºìŠ¤íŒ…
                if "EDATE" in df.columns:
                    df["EDATE"] = pd.to_datetime(df["EDATE"], errors="coerce")
                if "T_ID" in df.columns:
                    df["T_ID"] = pd.to_numeric(df["T_ID"], errors="coerce")

                # 2) íŠ¹ì • ì‚¬ìš©ì(T_ID=1) í•„í„°
                df_user = df[df["T_ID"] == 1]
                if df_user.empty:
                    st.error("T_ID=1 ì‚¬ìš©ì ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ë¨¼ì € â€˜í˜„ì¬ ì…ë ¥â€™ í˜ì´ì§€ì—ì„œ ë°ì´í„°ë¥¼ ì €ì¥í•˜ì„¸ìš”)")
                    return

                # 3) ì „ì²˜ë¦¬ (ì‹œê³„ì—´ ìš”ì•½)
                input_df = preprocess_followup(df_user)

                # 4) ëª¨ë¸ ë¡œë”©(10ë…„ í›„ ì˜ˆì¸¡ìš©)
                try:
                    models = load_models(kind="follow")
                except FileNotFoundError:
                    st.info("10ë…„ í›„ ì˜ˆì¸¡ìš© ëª¨ë¸(`follow_model_*.joblib`)ì´ ì—†ìŠµë‹ˆë‹¤.\n"
                            "ëª¨ë¸ íŒŒì¼ì„ `models/` í´ë”ì— ë„£ê³  ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
                    return

                # 5) ì˜ˆì¸¡/í™•ë¥ /ì¤‘ìš”ë„ ì¶œë ¥
                results_prob: dict[str, float] = {}
                feature_importances: dict[str, list[tuple[str, float]]] = {}

                st.subheader("ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼")
                for disease_name, model in models.items():
                    pred = model.predict(input_df)[0]
                    prob = float(model.predict_proba(input_df)[0][1])
                    results_prob[disease_name] = prob

                    if hasattr(model, "feature_importances_"):
                        importances = model.feature_importances_
                        feat_names = input_df.columns
                        top_idx = np.argsort(importances)[::-1][:3]
                        top_feats = [(feat_names[i], float(importances[i])) for i in top_idx]
                        feature_importances[disease_name] = top_feats
                    else:
                        feature_importances[disease_name] = []

                    st.write(
                        f"**{disease_name}**: {'ë°œìƒ ê°€ëŠ¥ì„± ë†’ìŒ' if pred==1 else 'ë°œìƒ ê°€ëŠ¥ì„± ë‚®ìŒ'} "
                        f"(í™•ë¥ : {prob:.2%})"
                    )

                # ìš”ì•½ í…Œì´ë¸”
                st.dataframe(
                    pd.DataFrame({
                        "ì§ˆë³‘": list(results_prob.keys()),
                        "ë°œìƒí™•ë¥ ": [f"{p:.1%}" for p in results_prob.values()]
                    }),
                    use_container_width=True
                )

                # ì¤‘ìš”ë„ í‘œ(ìˆì„ ë•Œë§Œ)
                for disease, feats in feature_importances.items():
                    if feats:
                        st.markdown(f"**{disease} ì˜í–¥ ìƒìœ„ í”¼ì²˜**")
                        st.table(pd.DataFrame(feats, columns=["í”¼ì²˜", "ì¤‘ìš”ë„"]))

                # 6) GPT ì„¤ëª…
                user_data = input_df.to_dict(orient="records")[0]
                explanation = generate_gpt_explanation(
                    user_data=user_data,
                    column_meaning=column_meaning,
                    results_prob=results_prob,
                    feature_importances=feature_importances,
                )

            st.subheader("ğŸ“ AIê°€ ì„¤ëª…í•´ì£¼ëŠ” ì˜ˆì¸¡ ê²°ê³¼")
            st.write(explanation)

        except FileNotFoundError:
            st.error("ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. `data/follow_sample.csv` ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        except Exception as e:
            st.error(f"ì—ëŸ¬ ë°œìƒ: {e}")
